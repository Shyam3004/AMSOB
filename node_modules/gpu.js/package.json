{
  "_args": [
    [
      {
        "raw": "gpu.js@^1.2.0",
        "scope": null,
        "escapedName": "gpu.js",
        "name": "gpu.js",
        "rawSpec": "^1.2.0",
        "spec": ">=1.2.0 <2.0.0",
        "type": "range"
      },
      "C:\\Users\\Dell\\Documents\\GitHub\\AMSOB\\node_modules\\brain.js"
    ]
  ],
  "_from": "gpu.js@^1.2.0",
  "_hasShrinkwrap": false,
  "_id": "gpu.js@1.9.1",
  "_location": "/gpu.js",
  "_nodeVersion": "8.9.4",
  "_npmOperationalInternal": {
    "host": "s3://npm-registry-packages",
    "tmp": "tmp/gpu.js_1.9.1_1540408553302_0.4782117645640964"
  },
  "_npmUser": {
    "name": "robertleeplummerjr",
    "email": "robertleeplummerjr@gmail.com"
  },
  "_npmVersion": "6.4.1",
  "_phantomChildren": {},
  "_requested": {
    "raw": "gpu.js@^1.2.0",
    "scope": null,
    "escapedName": "gpu.js",
    "name": "gpu.js",
    "rawSpec": "^1.2.0",
    "spec": ">=1.2.0 <2.0.0",
    "type": "range"
  },
  "_requiredBy": [
    "/brain.js"
  ],
  "_resolved": "https://registry.npmjs.org/gpu.js/-/gpu.js-1.9.1.tgz",
  "_shasum": "34e41a69668e000006d1a0bd66af72c66629f1c7",
  "_shrinkwrap": null,
  "_spec": "gpu.js@^1.2.0",
  "_where": "C:\\Users\\Dell\\Documents\\GitHub\\AMSOB\\node_modules\\brain.js",
  "author": {
    "name": "The gpu.js Team"
  },
  "bugs": {
    "url": "https://github.com/gpujs/gpu.js/issues"
  },
  "dependencies": {
    "acorn": "^5.1.1"
  },
  "description": "GPU Accelerated JavaScript",
  "devDependencies": {
    "babel-plugin-syntax-async-functions": "^6.5.0",
    "babel-preset-env": "^1.5.2",
    "browser-sync": "^2.18.2",
    "browserify": "^14.3.0",
    "del": "^3.0.0",
    "docdash": "^0.4.0",
    "gulp": "^3.9.1",
    "gulp-babel": "^6.1.2",
    "gulp-concat": "^2.6.0",
    "gulp-header": "^1.7.1",
    "gulp-jsbeautifier": "^2.1.0",
    "gulp-rename": "^1.2.2",
    "gulp-strip-comments": "^2.4.5",
    "gulp-uglify": "^1.5.2",
    "gulp-util": "^3.0.7",
    "jsdoc": "^3.5.0",
    "merge-stream": "^1.0.1",
    "qunit-assert-close": "^2.1.2",
    "qunitjs": "^2.3.2",
    "vinyl-buffer": "^1.0.0",
    "vinyl-source-stream": "^1.1.0"
  },
  "directories": {
    "doc": "doc",
    "test": "test"
  },
  "dist": {
    "integrity": "sha512-Hq/6EkJJd7htaE5yeNSVWv82zcVau3poZEohYVpB7KkoAopMooZFetcV47NJejlf0bFgYvcRpILZwmyEh/RE0A==",
    "shasum": "34e41a69668e000006d1a0bd66af72c66629f1c7",
    "tarball": "https://registry.npmjs.org/gpu.js/-/gpu.js-1.9.1.tgz",
    "fileCount": 45,
    "unpackedSize": 980657,
    "npm-signature": "-----BEGIN PGP SIGNATURE-----\r\nVersion: OpenPGP.js v3.0.4\r\nComment: https://openpgpjs.org\r\n\r\nwsFcBAEBCAAQBQJb0MTqCRA9TVsSAnZWagAAyxAQAJyx1/WVJEjVvxE8G27w\nkCmo9K0AP8HpKZGrVe3hEGwCmELtN754tgSZDxHjYBudmh7Z+X69E5ccBQfq\nveAEAxZTNgvJ5NO41ezYvbZMn6jVRQUNQEAAKATJghbsESi0fT0/acMka8pN\nh5Vk6xOxw9kwVqrITuiBVj4BkDLfernZ9kxNzh2BaLJBNBvQ9w42mSQOr44k\nVBW0RJ0gSGCdo5SBA/vSPpBOYsSgDSzQsJeBl4ewVOT66w4cNhDDXM9VEuvp\nWDN5PDfoJy/QZRP75MN1D3B7k6fIJVWNjVSVdA3oUAeYujAnNu91Q4M12bai\nLWHGJvyrMyEfaVCqReJByB/Y6dlM7oJ7nlH1rJ68Ql0pLxKhYLaaN2sAwETy\nVBupwwy1ogB85/8HMKPpkepNO8Mezku+9ecw/5rGhpBXckAJU2/pVk2V+wvN\njOU0pZnrpDm2pMRzZKQaxrxALqXt/EvGCApJ0FD9yZt0XCkfHXQeejPuEBuR\nyKEt9DLwfOZOYsLphCRwZ9tSMW46Bi3fv4FKSARsJ1CHqZz5HXbtwcL+2HPD\nBVzbrl6+KLUcWxyKdV4lGrhUCWUIeoplKXkLqo0McMmLC/1ATtAQP1rXYJs2\nmcXiVZIt9uJ1EZ9grp89IG1fk/GEIgCtrgW/lcBGTRyNJXSFAakcijvMQ7Dr\nFM4M\r\n=w5XD\r\n-----END PGP SIGNATURE-----\r\n"
  },
  "files": [
    "dist",
    "bin"
  ],
  "gitHead": "43bb07e879dc6f6085c45a825b6823e8a78e8ac8",
  "homepage": "http://gpu.rocks/",
  "keywords": [
    "gpgpu",
    "webgl"
  ],
  "license": "MIT",
  "main": "./dist/index.js",
  "maintainers": [
    {
      "name": "robertleeplummerjr",
      "email": "robertleeplummerjr@gmail.com"
    }
  ],
  "name": "gpu.js",
  "optionalDependencies": {},
  "readme": "[![Logo](http://gpu.rocks/img/ogimage.png)](http://gpu.rocks/)\n\n\n# GPU.js\nGPU.js is a JavaScript Acceleration library for GPGPU (General purpose computing on GPUs) in JavaScript. GPU.js will automatically compile simple JavaScript functions into shader language and run them on the GPU. In case a GPU is not available, the functions will still run in regular JavaScript.\n\n\n[![Join the chat at https://gitter.im/gpujs/gpu.js](https://badges.gitter.im/gpujs/gpu.js.svg)](https://gitter.im/gpujs/gpu.js?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\n[![Slack](https://slack.bri.im/badge.svg)](https://slack.bri.im)\n\n# What is this sorcery?\n\nMatrix multiplication written in GPU.js:\n\n```js\nconst gpu = new GPU();\n\n// Create the GPU accelerated function from a kernel\n// function that computes a single element in the\n// 512 x 512 matrix (2D array). The kernel function\n// is run in a parallel manner in the GPU resulting\n// in very fast computations! (...sometimes)\nconst matMult = gpu.createKernel(function(a, b) {\n    var sum = 0;\n    for (var i = 0; i < 512; i++) {\n        sum += a[this.thread.y][i] * b[i][this.thread.x];\n    }\n    return sum;\n}).setOutput([512, 512]);\n\n// Perform matrix multiplication on 2 matrices of size 512 x 512\nconst c = matMult(a, b);\n```\n\nYou can run a benchmark of this [here](http://gpu.rocks). Typically, it will run 1-15x faster depending on your hardware.\n\nOr alternatively you can experiment around with the [kernel playground here](http://gpu.rocks/playground)\n\n# Table of Contents\n\n* [Installation](#installation)\n* [`GPU` Options](#gpu-options)\n* [`gpu.createKernel` Options](#gpu-createkernel-options)\n* [Creating and Running Functions](#creating-and-running-functions)\n* [Accepting Input](#accepting-input)\n* [Graphical Output](#graphical-output)\n* [Combining Kernels](#combining-kernels)\n* [Create Kernel Map](#create-kernel-map)\n* [Adding Custom Functions](#adding-custom-functions)\n* [Adding Custom Functions Directly to Kernel](#adding-custom-functions-directly-to-kernel)\n* [Loops](#loops)\n* [Pipelining](#pipelining)\n* [Offscreen Canvas](#offscreen-canvas)\n* [Cleanup](#cleanup)\n* [Flattened typed array support](#flattened-typed-array-support)\n* [Supported Math functions](#supported-math-functions)\n* [Full API reference](#full-api-reference)\n* [Automatically-built Documentation](#automatically-built-documentation)\n* [Contributors](#contributors)\n* [Contributing](#contributing)\n* [Terms Explained](#terms-explained)\n* [License](#license)\n\n## Installation\n\n### npm\n\n```bash\nnpm install gpu.js --save\n```\n\n### yarn\n\n```bash\nyarn add gpu.js\n```\n\n[npm package](https://www.npmjs.com/package/gpu.js)\n\n### Browser\n\nDownload the latest version of GPU.js and include the files in your HTML page using the following tags:\n\n```html\n<script src=\"/path/to/js/gpu.min.js\"></script>\n```\n\nIn JavaScript, initialize the library:\n\n```js\nconst gpu = new GPU();\n```\n\n## `GPU` Options\nOptions are an object used to create an instance of `GPU`.  Example: `new GPU(options)`\n* `canvas`: `HTMLCanvasElement`.  Optional.  For sharing canvas.  Example: use THREE.js and GPU.js on same canvas.\n* `webGl`: `WebGL2RenderingContext` or `WebGLRenderingContext`.  For sharing rendering context.  Example: use THREE.js and GPU.js on same rendering context.\n\n## `gpu.createKernel` Options\nOptions are an object used to create a `kernel` or `kernelMap`.  Example: `gpu.createKernel(options)`\n* `output`: array or object that describes the output of kernel.\n  * as array: `[width]`, `[width, height]`, or `[width, height, depth]`\n  * as object: `{ x: width, y: height, z: depth }`\n* outputToTexture: boolean\n* graphical: boolean\n* loopMaxIterations: number\n* constants: object\n* wraparound: boolean\n* hardcodeConstants: boolean\n* floatTextures: boolean - input/working textures use float32 for each colour channel\n* floatOutput: boolean - output texture uses float32 for each  colour channel\n* fixIntegerDivisionAccuracy: boolean - some cards have accuracy issues dividing by factors of three and some other primes (most apple kit?). Default on for affected cards, disable if accuracy not required.\n* functions: array or boolean\n* nativeFunctions: object\n* subKernels: array\n* outputImmutable: boolean\n  * default to `false`\n  \n\n\n## Creating and Running Functions\nDepending on your output type, specify the intended size of your output. You cannot have an accelerated function that does not specify any output size.\n\nOutput size         \t |\tHow to specify output size   |\tHow to reference in kernel\n-----------------------|-------------------------------|--------------------------------\n1D\t\t\t               |\t`[length]`                   |\t`myVar[this.thread.x]`\n2D\t\t            \t   |\t`[width, height]`            |\t`myVar[this.thread.y][this.thread.x]`\n3D\t\t            \t   |\t`[width, height, depth]`     |\t`myVar[this.thread.z][this.thread.y][this.thread.x]`\n\n```js\nconst opt = {\n    output: [100]\n};\n```\n\nor\n\n```js\n// You can also use x, y, and z\nconst opt = {\n    output: { x: 100 }\n};\n```\n\nCreate the function you want to run on the GPU. The first input parameter to `createKernel` is a kernel function which will compute a single number in the output. The thread identifiers, `this.thread.x`, `this.thread.y` or `this.thread.z` will allow you to specify the appropriate behavior of the kernel function at specific positions of the output.\n\n```js\nconst myFunc = gpu.createKernel(function() {\n    return this.thread.x;\n}, opt);\n```\n\nThe created function is a regular JavaScript function, and you can use it like one.\n\n```js\nmyFunc();\n// Result: [0, 1, 2, 3, ... 99]\n```\n\nNote: Instead of creating an object, you can use the chainable shortcut methods as a neater way of specifying options.\n\n```js\nconst myFunc = gpu.createKernel(function() {\n    return this.thread.x;\n}).setOutput([100]);\n    \nmyFunc();\n// Result: [0, 1, 2, 3, ... 99]\n```\n## Accepting Input\n### Supported Input Types\n* Numbers\n* 1d Array\n* 2d Array\n* 3d Array\n* HTML Image\n* Array of HTML Images\nTo define an argument, simply add it to the kernel function like regular JavaScript.\n\n### Input Examples\n```js\nconst myFunc = gpu.createKernel(function(x) {\n    return x;\n}).setOutput([100]);\n    \nmyFunc(42);\n// Result: [42, 42, 42, 42, ... 42]\n```\n\nSimilarly, with array inputs:\n\n```js\nconst myFunc = gpu.createKernel(function(x) {\n    return x[this.thread.x % 3];\n}).setOutput([100]);\n    \nmyFunc([1, 2, 3]);\n// Result: [1, 2, 3, 1, ... 1 ]\n```\n\nAn HTML Image:\n\n```js\nconst myFunc = gpu.createKernel(function(image) {\n    const pixel = image[this.thread.y][this.thread.x];\n    this.color(pixel[0], pixel[1], pixel[2], pixel[3]);\n})\n  .setGraphical(true)\n  .setOutput([100]);\n\nconst image = new document.createElement('img');\nimage.src = 'my/image/source.png';\nimage.onload = () => {\n  myFunc(image);\n  // Result: colorful image\n};\n```\n\nAn Array of HTML Images:\n\n```js\nconst myFunc = gpu.createKernel(function(image) {\n    const pixel = image[this.thread.z][this.thread.y][this.thread.x];\n    this.color(pixel[0], pixel[1], pixel[2], pixel[3]);\n})\n  .setGraphical(true)\n  .setOutput([100]);\n\nconst image1 = new document.createElement('img');\nimage1.src = 'my/image/source1.png';\nimage1.onload = onload;\nconst image2 = new document.createElement('img');\nimage2.src = 'my/image/source2.png';\nimage2.onload = onload;\nconst image3 = new document.createElement('img');\nimage3.src = 'my/image/source3.png';\nimage3.onload = onload;\nconst totalImages = 3;\nlet loadedImages = 0;\nfunction onload() {\n  loadedImages++;\n  if (loadedImages === totalImages) {\n    myFunc([image1, image2, image3]);\n    // Result: colorful image composed of many images\n  }\n};\n```\n\n## Graphical Output\n\nSometimes, you want to produce a `canvas` image instead of doing numeric computations. To achieve this, set the `graphical` flag to `true` and the output dimensions to `[width, height]`. The thread identifiers will now refer to the `x` and `y` coordinate of the pixel you are producing. Inside your kernel function, use `this.color(r,g,b)` or `this.color(r,g,b,a)` to specify the color of the pixel.\n\nFor performance reasons, the return value of your function will no longer be anything useful. Instead, to display the image, retrieve the `canvas` DOM node and insert it into your page.\n\n```js\nconst render = gpu.createKernel(function() {\n    this.color(0, 0, 0, 1);\n})\n  .setOutput([20, 20])\n  .setGraphical(true);\n    \nrender();\n\nconst canvas = render.getCanvas();\ndocument.getElementsByTagName('body')[0].appendChild(canvas);\n```\n\nNote: To animate the rendering, use `requestAnimationFrame` instead of `setTimeout` for optimal performance. For more information, see [this](https://developer.mozilla.org/en-US/docs/Web/API/window/requestAnimationFrame).\n\n\n### Alpha\n\nCurrently, if you need alpha do something like enabling `premultipliedAlpha` with your own gl context:\n```js\nconst canvas = DOM.canvas(500, 500);\nconst gl = canvas.getContext('webgl2', { premultipliedAlpha: false });\n\nconst gpu = new GPU({\n  canvas,\n  webGl: gl\n});\nconst krender = gpu.createKernel(function(x) {\n  this.color(this.thread.x / 500, this.thread.y / 500, x[0], x[1]);\n})\n  .setOutput([500, 500])\n  .setGraphical(true);\n ```\n\n## Combining kernels\n\nSometimes you want to do multiple math operations on the gpu without the round trip penalty of data transfer from cpu to gpu to cpu to gpu, etc.  To aid this there is the `combineKernels` method.\n_**Note:**_ Kernels can have different output sizes.\n```js\nconst add = gpu.createKernel(function(a, b) {\n\treturn a + b;\n}).setOutput([20]);\n\nconst multiply = gpu.createKernel(function(a, b) {\n\treturn a * b;\n}).setOutput([20]);\n\nconst superKernel = gpu.combineKernels(add, multiply, function(a, b, c) {\n\treturn multiply(add(a[this.thread.x], b[this.thread.x]), c[this.thread.x]);\n});\n\nsuperKernel(a, b, c);\n```\nThis gives you the flexibility of using multiple transformations but without the performance penalty, resulting in a much much MUCH faster operation.\n\n## Create Kernel Map\n\nSometimes you want to do multiple math operations in one kernel, and save the output of each of those operations. An example is **Machine Learning** where the previous output is required for back propagation. To aid this there is the `createKernelMap` method.\n\n### object outputs\n```js\nconst megaKernel = gpu.createKernelMap({\n  addResult: function add(a, b) {\n    return a + b;\n  },\n  multiplyResult: function multiply(a, b) {\n    return a * b;\n  },\n}, function(a, b, c) {\n\treturn multiply(add(a[this.thread.x], b[this.thread.x]), c[this.thread.x]);\n});\n\nmegaKernel(a, b, c);\n// Result: { addResult: [], multiplyResult: [], result: [] }\n```\n### array outputs\n```js\nconst megaKernel = gpu.createKernelMap([\n  function add(a, b) {\n    return a + b;\n  },\n  function multiply(a, b) {\n    return a * b;\n  }\n], function(a, b, c) {\n\treturn multiply(add(a[this.thread.x], b[this.thread.x]), c[this.thread.x]);\n});\n\nmegaKernel(a, b, c);\n// Result: [ [], [] ].result []\n```\nThis gives you the flexibility of using parts of a single transformation without the performance penalty, resulting in much much _MUCH_ faster operation.\n\n## Adding custom functions\nDo you have a custom function you'd like to use on the gpu? Although limited, you can:\n```js\ngpu.addFunction(function mySuperFunction(a, b) {\n\treturn a - b;\n});\nfunction anotherFunction(value) {\n\treturn value + 1;\n}\ngpu.addFunction(anotherFunction);\nconst kernel = gpu.createKernel(function(a, b) {\n\treturn anotherFunction(mySuperFunction(a[this.thread.x], b[this.thread.x]));\n}).setOutput([20]);\n```\n\n## Adding custom functions directly to kernel\n```js\nfunction mySuperFunction(a, b) {\n\treturn a - b;\n}\nconst kernel = gpu.createKernel(function(a, b) {\n\treturn mySuperFunction(a[this.thread.x], b[this.thread.x]);\n})\n  .setOutput([20])\n  .setFunctions([mySuperFunction]);\n\n```\n\n## Loops\n* Any loops defined inside the kernel must have a maximum iteration count defined by the loopMaxIterations option.\n* Other than defining the iterations by a constant or fixed value as shown [Dynamic sized via constants](dynamic-sized-via-constants), you can also simply pass the number of iterations as a variable to the kernel\n\n### Dynamic sized via constants\n```js\nconst matMult = gpu.createKernel(function(a, b) {\n    var sum = 0;\n    for (var i = 0; i < this.constants.size; i++) {\n        sum += a[this.thread.y][i] * b[i][this.thread.x];\n    }\n    return sum;\n}, {\n  constants: { size: 512 },\n  output: [512, 512],\n});\n```\n\n### Fixed sized\n```js\nconst matMult = gpu.createKernel(function(a, b) {\n    var sum = 0;\n    for (var i = 0; i < 512; i++) {\n        sum += a[this.thread.y][i] * b[i][this.thread.x];\n    }\n    return sum;\n}).setOutput([512, 512]);\n```\n\n## Pipelining\n[Pipeline](https://en.wikipedia.org/wiki/Pipeline_(computing)) is a feature where values are sent directly from kernel to kernel via a texture.\nThis results in extremely fast computing.  This is achieved with the kernel option `outputToTexture: boolean` option or by calling `kernel.setOutputToTexture(true)`\n\n## Offscreen Canvas\nGPU.js supports offscreen canvas where available.  Here is an example of how to use it with two files, `gpu-worker.js`, and `index.js`:\n\nfile: `gpu-worker.js`\n```js\nimportScripts('path/to/gpu.js');\nonmessage = function() {\n  // define gpu instance\n  const gpu = new GPU();\n  \n  // input values\n  const a = [1,2,3];\n  const b = [3,2,1];\n  \n  // setup kernel\n  const kernel = gpu.createKernel(function(a, b) {\n    return a[this.thread.x] - b[this.thread.x];\n  })\n    .setOutput([3]);\n  \n  // output some results!\n  postMessage(kernel(a, b));\n};\n```\n\nfile: `index.js`\n```js\nvar worker = new Worker('gpu-worker.js');\nworker.onmessage = function(e) {\n  var result = e.data;\n  console.log(result);\n};\n```\n\n## Cleanup\n* for instances of `GPU` use the `destroy` method.  Example: `gpu.destroy()`\n* for instances of `Kernel` use the `destroy` method.  Example: `kernel.destroy()`\n\n## Flattened typed array support\nTo use the useful `x`, `y`, `z` `thread` lookup api inside of GPU.js, and yet use flattened arrays, there is the `Input` type.\nThis is generally much faster for when sending values to the gpu, especially with larger data sets.  Usage example:\n```js\nimport GPU, { input } from 'gpu.js';\nconst gpu = new GPU();\nconst kernel = gpu.createKernel(function(a, b) {\n  return a[this.thread.y][this.thread.x] + b[this.thread.y][this.thread.x];\n}).setOutput([3,3]);\n\n\nkernel(input(new Float32Array([1,2,3,4,5,6,7,8,9]), [3, 3]), input(new Float32Array([1,2,3,4,5,6,7,8,9]), [3, 3]));\n```\n\nNote: `GPU.input(value, size)` is a simple pointer for `new GPU.Input(value, size)`\n\n## Supported Math functions\n\nSince the code running in the kernel is actually compiled to GLSL code, not all functions from the JavaScript Math module are supported.\n\nThis is a list of the supported ones:\n\n```\nabs\nacos\nasin\natan\natan2\nceil\ncos\nexp\nfloor\nlog\nlog2\nmax\nmin\nround\nsign \nsin\nsqrt\ntan\n```\n\n\n## Full API Reference\n\nYou can find a [complete API reference here](https://doxdox.org/gpujs/gpu.js/1.2.0).\n\n## Automatically-built Documentation\n\nDocumentation of the codebase is [automatically built](https://github.com/gpujs/gpu.js/wiki/Automatic-Documentation).\n\n## Contributors\n \n* Fazli Sapuan\n* Eugene Cheah\n* Matthew Saw\n* Robert Plummer\n* Abhishek Soni\n* Juan Cazala\n* Daniel X Moore\n* Mark Theng\n* Varun Patro\n \n## Contributing\n \nContributors are welcome! Create a merge request to the `develop` branch and we\nwill gladly review it. If you wish to get write access to the repository,\nplease email us and we will review your application and grant you access to\nthe `develop` branch.\n \nWe promise never to pass off your code as ours.\n\n## Terms Explained\n* Kernel - A function that is tightly coupled to program that runs on the Graphic Processor\n* Texture - A graphical artifact that is packed with data, in the case of GPU.js, bit shifted parts of a 32 bit floating point decimal\n\n## License \n\nThe MIT License\n\nCopyright (c) 2018 GPU.js Team\n \nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in\nall copies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\nTHE SOFTWARE.\n",
  "readmeFilename": "README.md",
  "repository": {
    "type": "git",
    "url": "git+https://github.com/gpujs/gpu.js.git"
  },
  "scripts": {
    "build-docs": "jsdoc -c jsdoc.json src -r -d doc --debug && gulp injectCSS",
    "make": "gulp build && gulp beautify && gulp minify",
    "setup": "npm i -g gulp-cli",
    "test": "echo \"Error: no test specified\" && exit 1"
  },
  "version": "1.9.1"
}
